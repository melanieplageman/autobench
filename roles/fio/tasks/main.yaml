- name: Print nr_hw_queues value
  debug: var=nr_hw_queues

- name: Install fio
  become: yes
  apt: name=fio

- name: Install schedtool
  become: yes
  apt: name=schedtool

- name: Copy fio job file to target host
  template:
    src: "templates/workloads/{{ workload_id }}_{{ workload_size }}.j2"
    dest: "{{ ansible_user_dir }}/job.fio"
    mode: "0755"
  when: fio_job_file is not defined

- name: Create an fio output directory on the target host
  file:
    path: fio_output
    state: directory

- name: Run fio jobs
  command: >
    fio
      --directory="{{ fio_target_directory | quote }}"
      --output-format=json+
      --output="{{ ansible_user_dir }}/fio_output/{{ fio_result_file }}"
    "{{ ansible_user_dir }}/job.fio"
  args:
    chdir: "{{ fio_target_directory }}"

- name: Delete output of fio write job 1
  file:
    path: "{{ fio_target_directory }}/{{ fio_write_job1_data_filename }}"
    state: absent
  when: fio_write_job1_data_filename is defined

- name: Delete output of fio write job 2
  file:
    path: "{{ fio_target_directory }}/{{ fio_write_job2_data_filename }}"
    state: absent
  when: fio_write_job2_data_filename is defined

- name: Delete fio read job 3 file
  file:
    path: "{{ fio_target_directory }}/{{ fio_read_job3_data_filename }}"
    state: absent
  when: delete_fio_read_files == 1 and fio_read_job3_data_filename is defined

- name: Delete fio read job 4 file
  file:
    path: "{{ fio_target_directory }}/{{ fio_read_job4_data_filename }}"
    state: absent
  when: delete_fio_read_files == 1 and fio_read_job4_data_filename is defined

- name: Copy fio output file from host
  fetch:
    src: "{{ ansible_user_dir }}/fio_output/{{ fio_result_file }}"
    dest: "{{ fio_results_directory }}"
    flat: yes

# Ensure that Ansible's DEFAULT_JINJA2_NATIVE configuration is used
# https://docs.ansible.com/ansible/latest/reference_appendices/config.html#default-jinja2-native
# Otherwise, the INSERT will fail due to one of the io scheduler configuration values being undefined

# This step only works if the database schema has already been loaded
- name: Insert run settings and fio results to database
  community.general.postgresql_query:
    db: "{{ fio_results_dbname }}"
    login_user: "{{ fio_results_db_user }}"
    login_password: "{{ fio_results_db_password }}"
    login_host: "{{ fio_results_db_host }}"
    ssl_mode: "{{ fio_results_ssl_mode }}"
    query: >
      INSERT INTO run (
      schedtool,
      settings,
      workload_id,
      disk_id,
      disk_device,
      vm_id,
      nr_hw_queues,
      kernel_nr_requests, kernel_max_sectors_kb,
      kernel_read_ahead_kb, kernel_queue_depth,
      kernel_wbt_lat_usec, kernel_rotational,
      kernel_io_scheduler,
      kernel_mqdeadline_fifo_batch, kernel_mqdeadline_writes_starved,
      kernel_bfq_low_latency,
      data
      )
      VALUES (
        %(schedtool)s,
        %(settings)s,
        %(workload_id)s,
        (SELECT id FROM disk WHERE disk.size_gb = %(disk_size_gb)s),
        %(disk_device)s,
        (SELECT id FROM vm WHERE vm.instance_type = %(vm_instance_type)s),
        %(nr_hw_queues)s,
        %(kernel_nr_requests)s, %(kernel_max_sectors_kb)s,
        %(kernel_read_ahead_kb)s, %(kernel_queue_depth)s,
        %(kernel_wbt_lat_usec)s, %(kernel_rotational)s,
        %(kernel_io_scheduler)s,
        %(kernel_mqdeadline_fifo_batch)s, %(kernel_mqdeadline_writes_starved)s,
        %(kernel_bfq_low_latency)s,
        %(data)s
      )
    named_args:
      schedtool: "{{ schedtool }}"
      settings: "{{ settings }}"
      workload_id: "{{ workload_id }}"
      disk_size_gb: "{{ hostvars[inventory_hostname]['vm_data_disk_specs']['size_gb'] }}"
      disk_device: "{{ hostvars[inventory_hostname]['vm_data_disk_specs']['device'] }}"
      vm_instance_type: "{{ hostvars[inventory_hostname]['vm_instance_info']['specs']['instance_type'] }}"
      nr_hw_queues: "{{ nr_hw_queues if (nr_hw_queues is defined) else none | default(none) }}"
      kernel_nr_requests: "{{ disk_kernel_nr_requests }}"
      kernel_max_sectors_kb: "{{ disk_kernel_max_sectors_kb }}"
      kernel_read_ahead_kb: "{{ disk_kernel_read_ahead_kb }}"
      kernel_queue_depth: "{{ disk_kernel_queue_depth }}"
      kernel_wbt_lat_usec: "{{ disk_kernel_wbt_lat_usec }}"
      kernel_rotational: "{{ disk_kernel_rotational }}"
      kernel_io_scheduler: "{{ disk_kernel_io_scheduler }}"
      kernel_mqdeadline_fifo_batch: "{{ disk_kernel_mqdeadline_fifo_batch if (disk_kernel_mqdeadline_fifo_batch is defined) else none | default(none) }}"
      kernel_mqdeadline_writes_starved: "{{ disk_kernel_mqdeadline_writes_starved if (disk_kernel_mqdeadline_writes_starved is defined) else none | default(none) }}"
      kernel_bfq_low_latency: "{{ disk_kernel_bfq_low_latency if (disk_kernel_bfq_low_latency is defined) else none | default(none) }}"
      data: "{{ lookup('file', (fio_results_directory, fio_result_file) | path_join) | string }}"
  delegate_to: localhost

# TODO: condition this on the database INSERT being successful
- name: Delete fio output file from localhost
  file:
    path: "{{ fio_results_directory }}/{{fio_result_file}}"
    state: absent
  delegate_to: localhost

# vim: set ft=yaml.ansible:
